<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://postyear.github.io</id>
    <title>Postyear</title>
    <updated>2021-03-11T10:33:08.909Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://postyear.github.io"/>
    <link rel="self" href="https://postyear.github.io/atom.xml"/>
    <subtitle>Postyear，记录一个普通程序员的生活</subtitle>
    <logo>https://postyear.github.io/images/avatar.png</logo>
    <icon>https://postyear.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, Postyear</rights>
    <entry>
        <title type="html"><![CDATA[2014年流形的聚类算法(Clustering by fast search and find of density peaksd)]]></title>
        <id>https://postyear.github.io/post/2014-nian-liu-xing-de-ju-lei-suan-fa-clustering-by-fast-search-and-find-of-density-peaksd/</id>
        <link href="https://postyear.github.io/post/2014-nian-liu-xing-de-ju-lei-suan-fa-clustering-by-fast-search-and-find-of-density-peaksd/">
        </link>
        <updated>2021-03-11T10:10:46.000Z</updated>
        <summary type="html"><![CDATA[<p>最近在学习聚类算法，很多聚类算法需要指定聚类个数，而聚类个数对聚类结果的影响非常大。</p>
<p>聚类个数一般作为kmeans等方法的前置参数。但也有一些聚类算法克服了缺点(变相转移)，比如：</p>
<p>1.Affinity Propagation（AP）聚类</p>
<p><strong>基本思想：</strong><br>
将全部样本看作网络的节点，然后通过网络中各条边的消息传递计算出各样本的聚类中心。聚类过程中，共有两种消息在各节点间传递，分别是吸引度( responsibility)和归属度(availability) 。AP算法通过迭代过程不断更新每一个点的吸引度和归属度值，直到产生m个高质量的Exemplar（类似于质心），同时将其余的数据点分配到相应的聚类中。</p>
<p>已被sklearn.cluster收录</p>
<p><strong>优点：</strong><br>
无需指定K值，而且最终得到的聚类中心就是原数据中的点，收敛效果远胜于Kemans<br>
<strong>缺点：</strong><br>
计算复杂度大，时间长</p>
<p>2.meanshift<br>
<strong>基本思想</strong><br>
Mean shift 算法是基于核密度估计的爬山算法，可用于聚类、图像分割、跟踪等。 MeanShift，顾名思义，由Mean（均值）和shift（偏移）组成。也就是有一个点x，周围有很多点xi，我们计算点x移动到每个点所需要的偏移量之和，求平均，就得到平均偏移量。该偏移量包含大小和方向 ，方向就是周围分布密集的方向。然后点x往平均偏移量方向移动，再以此为新起点，不断迭代直到满足一定条件结束。</p>
<p>已被sklearn.cluster收录</p>
<p><strong>优点：</strong><br>
几乎是没有参数的，带宽可以用sklearn自带的函数估计出来。</p>
<p><strong>缺点</strong><br>
聚类性能不是那么强</p>
]]></summary>
        <content type="html"><![CDATA[<p>最近在学习聚类算法，很多聚类算法需要指定聚类个数，而聚类个数对聚类结果的影响非常大。</p>
<p>聚类个数一般作为kmeans等方法的前置参数。但也有一些聚类算法克服了缺点(变相转移)，比如：</p>
<p>1.Affinity Propagation（AP）聚类</p>
<p><strong>基本思想：</strong><br>
将全部样本看作网络的节点，然后通过网络中各条边的消息传递计算出各样本的聚类中心。聚类过程中，共有两种消息在各节点间传递，分别是吸引度( responsibility)和归属度(availability) 。AP算法通过迭代过程不断更新每一个点的吸引度和归属度值，直到产生m个高质量的Exemplar（类似于质心），同时将其余的数据点分配到相应的聚类中。</p>
<p>已被sklearn.cluster收录</p>
<p><strong>优点：</strong><br>
无需指定K值，而且最终得到的聚类中心就是原数据中的点，收敛效果远胜于Kemans<br>
<strong>缺点：</strong><br>
计算复杂度大，时间长</p>
<p>2.meanshift<br>
<strong>基本思想</strong><br>
Mean shift 算法是基于核密度估计的爬山算法，可用于聚类、图像分割、跟踪等。 MeanShift，顾名思义，由Mean（均值）和shift（偏移）组成。也就是有一个点x，周围有很多点xi，我们计算点x移动到每个点所需要的偏移量之和，求平均，就得到平均偏移量。该偏移量包含大小和方向 ，方向就是周围分布密集的方向。然后点x往平均偏移量方向移动，再以此为新起点，不断迭代直到满足一定条件结束。</p>
<p>已被sklearn.cluster收录</p>
<p><strong>优点：</strong><br>
几乎是没有参数的，带宽可以用sklearn自带的函数估计出来。</p>
<p><strong>缺点</strong><br>
聚类性能不是那么强</p>
<!-- more -->
<p>3.密度峰值</p>
<p><strong>核心思想</strong><br>
对聚类中心的刻画上，而且认为聚类中心同时具有以下两种特点：<br>
1）本身的密度大，即它被密度均不超过它的邻居包围<br>
2）与其他密度更大的数据点之间的“距离”相对更大</p>
<p>这个算法是14年刚出现的，从GitHub的搜索结果来看也很流行，不同语言的都有。简单来说分四步：<br>
第1步，求每个点的密度rho。点的密度就是，以点为中心，以dc为半径，画一个小圆圈，数数里面几个点，圆圈中点的个数就是点的密度。（还可以用高斯核密度求点的密度，求出来的密度是连续型的）<br>
第2步，计算每个点的delta。假设有一个点x，求比点x的密度大的且距离点x最近的那个点y，那么点x与点y之间的距离，就是点x的delta，就这样遍历所有点，把每个点的delta都求出来（注意，delta是距离，谁和谁的距离？x和y的距离，y是谁？y就是比x密度大，且距离x最近的那个点，要满足两个条件，密度比x大且距离最近）<br>
第3步，每个点的密度rho和delta都求出来了，以rho为横坐标，delta为纵坐标，画个二维图，图中右上角的那几个点就是聚类中心，也就是rho和delta都很大的那几个点。（为什么？因为聚类中心有个特点，密度很大，且与密度比它大的点的距离也很大）<br>
第4步，找到聚类中心了，就可以扩展聚类簇了，按照rho从大到小的顺序进行聚类扩展。<br>
转自知乎，链接：https://www.zhihu.com/question/65977238/answer/923739282</p>
<p>密度峰值算法需要输入参数t，为百分数的整数部分，如2%，用于确定截断距离Dc。<strong>作者建议取1%-2%</strong>。 one can choose d c so that the average number of neighbors is around 1 to 2% of the total number of points in the data set.(论文原话)</p>
<p>可以参阅文章：https://www.cnblogs.com/nolonely/p/6964852.html</p>
<p>python实现代码：<br>
1.https://github.com/Larry213021/Clustering-by-fast-search-and-find-of-density-peaks/blob/main/classification/CFSDP(%E4%BB%A5t%E7%82%BA%E5%9F%BA%E6%BA%96).py<br>
2.https://github.com/Kingzy-Chen/DensityPeakCluster</p>
<p><strong>优点：</strong><br>
无需k值，性能过得去<br>
<strong>缺点：</strong><br>
似乎在高维数据上表现不佳；</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[入侵检测中使用的数据增强]]></title>
        <id>https://postyear.github.io/post/ru-qin-jian-ce-zhong-shi-yong-de-shu-ju-zeng-qiang/</id>
        <link href="https://postyear.github.io/post/ru-qin-jian-ce-zhong-shi-yong-de-shu-ju-zeng-qiang/">
        </link>
        <updated>2021-03-10T12:51:22.000Z</updated>
        <summary type="html"><![CDATA[<p>在入侵检测中，一般特征选择用得非常多，数据增强技术使用比较少。但也有。</p>
<p>数据增强在神经网络中更常见，主要用来防止过拟合，用于dataset较小的时候。</p>
<p>之前对神经网络有过了解的人都知道，虽然一个两层网络在理论上可以拟合所有的分布，但是并不容易学习得到。因此在实际中，我们通常会增加神经网络的深度和广度，从而让神经网络的学习能力增强，便于拟合训练数据的分布情况。在卷积神经网络中，有人实验得到，深度比广度更重要。</p>
<p>增强后的数据维度没有发生变化。今天记录的就是这样一种有监督的数据增强方法，计算特征的边缘密度比(marginal density ratio)替换原特征，可以加速训练。最初是国外一篇论文提出的，被用于基于SVM的入侵检测论文中，尽管作者表明可以替换为任意分类器，但应该最适合SVM。步骤如下：</p>
<figure data-type="image" tabindex="1"><img src="https://postyear.github.io/post-images/1615381362646.png" alt="" loading="lazy"></figure>
<p>作者是用R语言实现的，R包不太会用，后来就没有用。链接见下方：</p>
]]></summary>
        <content type="html"><![CDATA[<p>在入侵检测中，一般特征选择用得非常多，数据增强技术使用比较少。但也有。</p>
<p>数据增强在神经网络中更常见，主要用来防止过拟合，用于dataset较小的时候。</p>
<p>之前对神经网络有过了解的人都知道，虽然一个两层网络在理论上可以拟合所有的分布，但是并不容易学习得到。因此在实际中，我们通常会增加神经网络的深度和广度，从而让神经网络的学习能力增强，便于拟合训练数据的分布情况。在卷积神经网络中，有人实验得到，深度比广度更重要。</p>
<p>增强后的数据维度没有发生变化。今天记录的就是这样一种有监督的数据增强方法，计算特征的边缘密度比(marginal density ratio)替换原特征，可以加速训练。最初是国外一篇论文提出的，被用于基于SVM的入侵检测论文中，尽管作者表明可以替换为任意分类器，但应该最适合SVM。步骤如下：</p>
<figure data-type="image" tabindex="1"><img src="https://postyear.github.io/post-images/1615381362646.png" alt="" loading="lazy"></figure>
<p>作者是用R语言实现的，R包不太会用，后来就没有用。链接见下方：</p>
<!-- more -->
<p><strong>Paper</strong>：A novel approach to intrusion detection using<br>
SVM ensemble with feature augmentation<br>
<strong>Github</strong>：https://github.com/ShanLu92/FeaAug/blob/4df07a5c099b8e4b234ba3156208c2b671c127b2/R/LMDRT.R&gt;</p>
<!-- more -->
<p>还有这篇论文Augboost(Gradient Boosting Enhanced with Step-Wise Feature Augmentation)也是提出了一种新的数据增强技术，无监督，百度可以查到介绍，<br>
https://github.com/augboost-anon/augboost</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[韩山]]></title>
        <id>https://postyear.github.io/post/han-shan-very-hot/</id>
        <link href="https://postyear.github.io/post/han-shan-very-hot/">
        </link>
        <updated>2021-02-21T12:21:34.000Z</updated>
        <content type="html"><![CDATA[<p>韩山，比想象中好玩！就是今天天太热了！<br>
<img src="https://postyear.github.io/post-images/1613910525338.jpg" alt="" loading="lazy"><br>
<img src="https://postyear.github.io/post-images/1613910705228.jpg" alt="" loading="lazy"><br>
<img src="https://postyear.github.io/post-images/1613910716704.jpg" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[第一天]]></title>
        <id>https://postyear.github.io/post/di-yi-tian/</id>
        <link href="https://postyear.github.io/post/di-yi-tian/">
        </link>
        <updated>2021-02-18T13:11:28.000Z</updated>
        <content type="html"><![CDATA[<p>开通博客的第一天</p>
]]></content>
    </entry>
</feed>